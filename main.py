import os
import json
import streamlit as st
from dotenv import load_dotenv
from langchain.vectorstores import Chroma
from langchain.schema import Document
from langchain_openai import OpenAIEmbeddings

# âœ… 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë”©
load_dotenv()
openai_key = os.getenv("OPENAI_API_KEY")

# âœ… 2. JSON íŒŒì¼ ê²½ë¡œ ì„¤ì •
ELEMENTARY_JSON_PATH = "data/achievement_standards.json"
MIDDLE_JSON_PATH = "data/middleschool/middle_standards.json"
HIGH_JSON_PATH = "data/highschool/high_standards.json"

# âœ… 3. ì„ë² ë”© ëª¨ë¸ ì„¤ì •
embedding_model = OpenAIEmbeddings(model="text-embedding-3-small")

# âœ… 4. ì´ˆë“± í•„í„°ë§ í•¨ìˆ˜ (í•™ë…„+ê³¼ëª©)
def load_filtered_documents(json_path, selected_grade, selected_subject):
    docs = []
    with open(json_path, "r", encoding="utf-8") as f:
        data = json.load(f)
    if selected_grade in data and selected_subject in data[selected_grade]:
        for content in data[selected_grade][selected_subject]:
            docs.append(Document(
                page_content=content,
                metadata={"í•™ë…„": selected_grade, "êµê³¼": selected_subject}
            ))
    return docs

# âœ… 5. ì¤‘í•™êµ í•„í„°ë§ í•¨ìˆ˜ (ê³¼ëª©ë§Œ)
def load_filtered_documents_middle(json_path, selected_subject):
    docs = []
    with open(json_path, "r", encoding="utf-8") as f:
        data = json.load(f)
    if selected_subject in data:
        for content in data[selected_subject]:
            docs.append(Document(
                page_content=content,
                metadata={"êµê³¼": selected_subject}
            ))
    return docs

# âœ… 6. ê³ ë“±í•™êµ í•„í„°ë§ í•¨ìˆ˜ (ê³¼ëª©ë§Œ)
def load_filtered_documents_high(json_path, selected_subject):
    docs = []
    with open(json_path, "r", encoding="utf-8") as f:
        data = json.load(f)
    if selected_subject in data:
        for content in data[selected_subject]:
            docs.append(Document(
                page_content=content,
                metadata={"êµê³¼": selected_subject}
            ))
    return docs

# âœ… 7. Streamlit UI
st.set_page_config(page_title="ì„±ì·¨ê¸°ì¤€ ì¶”ì²œê¸°", page_icon="ğŸ¯")
st.title("ğŸ¯ ì„±ì·¨ê¸°ì¤€ ì¶”ì²œê¸°")

tab1, tab2, tab3 = st.tabs(["ğŸ§’ ì´ˆë“±í•™êµ", "ğŸ« ì¤‘í•™êµ", "ğŸ“ ê³ ë“±í•™êµ"])

# âœ… ì´ˆë“±í•™êµ íƒ­
with tab1:
    st.markdown("**ìˆ˜ì—… í™œë™ì„ ì…ë ¥í•˜ë©´, ê´€ë ¨ëœ ì´ˆë“±í•™êµ ì„±ì·¨ê¸°ì¤€ì„ ì¶”ì²œí•©ë‹ˆë‹¤.**")
    grade_options = ["1~2í•™ë…„", "3~4í•™ë…„", "5~6í•™ë…„"]
    subject_options = ["êµ­ì–´", "ìˆ˜í•™", "ì‚¬íšŒ", "ê³¼í•™", "ë„ë•", "ì²´ìœ¡", "ìŒì•…", "ë¯¸ìˆ ", "ì‹¤ê³¼"]
    selected_grade = st.selectbox("ğŸ“˜ í•™ë…„ ì„ íƒ", grade_options, key="elem_grade")
    selected_subject = st.selectbox("ğŸ“™ êµê³¼ ì„ íƒ", subject_options, key="elem_subject")
    user_input = st.text_area("ğŸ“ ìˆ˜ì—… í™œë™ì„ ì…ë ¥í•˜ì„¸ìš”", height=150, key="elem_input")

    if st.button("ğŸ” ì„±ì·¨ê¸°ì¤€ ì°¾ê¸°", key="elem_search"):
        if not user_input.strip():
            st.warning("ìˆ˜ì—… í™œë™ ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            with st.spinner("AIê°€ ì„±ì·¨ê¸°ì¤€ì„ ì°¾ê³  ìˆì–´ìš”..."):
                filtered_docs = load_filtered_documents(ELEMENTARY_JSON_PATH, selected_grade, selected_subject)
                if not filtered_docs:
                    st.error(f"{selected_grade} {selected_subject} ì„±ì·¨ê¸°ì¤€ì´ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    vectorstore = Chroma.from_documents(filtered_docs, embedding=embedding_model)
                    results_with_scores = vectorstore.similarity_search_with_score(user_input, k=10)

                    unique_contents = set()
                    final_results = []
                    for doc, score in results_with_scores:
                        content = doc.page_content.strip()
                        meta = doc.metadata
                        if meta.get("í•™ë…„") == selected_grade and meta.get("êµê³¼") == selected_subject:
                            if content not in unique_contents:
                                unique_contents.add(content)
                                final_results.append((content, score))
                        if len(final_results) == 5:
                            break

                    if final_results:
                        st.subheader("ğŸ“Œ ì¶”ì²œ ì„±ì·¨ê¸°ì¤€")
                        for i, (content, score) in enumerate(final_results, 1):
                            st.markdown(f"**{i}.** {content}")
                            st.caption(f"ğŸ§  ìœ ì‚¬ë„ ì ìˆ˜: `{score:.3f}`")
                    else:
                        st.info("ê´€ë ¨ ì„±ì·¨ê¸°ì¤€ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ìš”. ì…ë ¥ì„ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”.")

# âœ… ì¤‘í•™êµ íƒ­
with tab2:
    st.markdown("**ìˆ˜ì—… í™œë™ì„ ì…ë ¥í•˜ë©´, ê´€ë ¨ëœ ì¤‘í•™êµ ì„±ì·¨ê¸°ì¤€ì„ ì¶”ì²œí•©ë‹ˆë‹¤.**")
    subject_options_m = ["ê³¼í•™", "ë¯¸ìˆ ", "ìˆ˜í•™"]
    selected_subject_m = st.selectbox("ğŸ“™ êµê³¼ ì„ íƒ", subject_options_m, key="middle_subject")
    user_input_m = st.text_area("ğŸ“ ìˆ˜ì—… í™œë™ì„ ì…ë ¥í•˜ì„¸ìš”", height=150, key="middle_input")

    if st.button("ğŸ” ì„±ì·¨ê¸°ì¤€ ì°¾ê¸°", key="middle_search"):
        if not user_input_m.strip():
            st.warning("ìˆ˜ì—… í™œë™ ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            with st.spinner("AIê°€ ì„±ì·¨ê¸°ì¤€ì„ ì°¾ê³  ìˆì–´ìš”..."):
                filtered_docs = load_filtered_documents_middle(MIDDLE_JSON_PATH, selected_subject_m)
                if not filtered_docs:
                    st.error(f"{selected_subject_m} êµê³¼ ì„±ì·¨ê¸°ì¤€ì´ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    vectorstore = Chroma.from_documents(filtered_docs, embedding=embedding_model)
                    results_with_scores = vectorstore.similarity_search_with_score(user_input_m, k=10)

                    unique_contents = set()
                    final_results = []
                    for doc, score in results_with_scores:
                        content = doc.page_content.strip()
                        meta = doc.metadata
                        if meta.get("êµê³¼") == selected_subject_m:
                            if content not in unique_contents:
                                unique_contents.add(content)
                                final_results.append((content, score))
                        if len(final_results) == 5:
                            break

                    if final_results:
                        st.subheader("ğŸ“Œ ì¶”ì²œ ì„±ì·¨ê¸°ì¤€")
                        for i, (content, score) in enumerate(final_results, 1):
                            st.markdown(f"**{i}.** {content}")
                            st.caption(f"ğŸ§  ìœ ì‚¬ë„ ì ìˆ˜: `{score:.3f}`")
                    else:
                        st.info("ê´€ë ¨ ì„±ì·¨ê¸°ì¤€ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ìš”. ì…ë ¥ì„ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”.")

# âœ… ê³ ë“±í•™êµ íƒ­
with tab3:
    st.markdown("**ìˆ˜ì—… í™œë™ì„ ì…ë ¥í•˜ë©´, ê´€ë ¨ëœ ê³ ë“±í•™êµ ì„±ì·¨ê¸°ì¤€ì„ ì¶”ì²œí•©ë‹ˆë‹¤.**")
    subject_options_h = ["ë¯¸ìˆ "]
    selected_subject_h = st.selectbox("ğŸ“™ êµê³¼ ì„ íƒ", subject_options_h, key="high_subject")
    user_input_h = st.text_area("ğŸ“ ìˆ˜ì—… í™œë™ì„ ì…ë ¥í•˜ì„¸ìš”", height=150, key="high_input")

    if st.button("ğŸ” ì„±ì·¨ê¸°ì¤€ ì°¾ê¸°", key="high_search"):
        if not user_input_h.strip():
            st.warning("ìˆ˜ì—… í™œë™ ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            with st.spinner("AIê°€ ì„±ì·¨ê¸°ì¤€ì„ ì°¾ê³  ìˆì–´ìš”..."):
                filtered_docs = load_filtered_documents_high(HIGH_JSON_PATH, selected_subject_h)
                if not filtered_docs:
                    st.error(f"{selected_subject_h} êµê³¼ ì„±ì·¨ê¸°ì¤€ì´ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    vectorstore = Chroma.from_documents(filtered_docs, embedding=embedding_model)
                    results_with_scores = vectorstore.similarity_search_with_score(user_input_h, k=10)

                    unique_contents = set()
                    final_results = []
                    for doc, score in results_with_scores:
                        content = doc.page_content.strip()
                        meta = doc.metadata
                        if meta.get("êµê³¼") == selected_subject_h:
                            if content not in unique_contents:
                                unique_contents.add(content)
                                final_results.append((content, score))
                        if len(final_results) == 5:
                            break

                    if final_results:
                        st.subheader("ğŸ“Œ ì¶”ì²œ ì„±ì·¨ê¸°ì¤€")
                        for i, (content, score) in enumerate(final_results, 1):
                            st.markdown(f"**{i}.** {content}")
                            st.caption(f"ğŸ§  ìœ ì‚¬ë„ ì ìˆ˜: `{score:.3f}`")
                    else:
                        st.info("ê´€ë ¨ ì„±ì·¨ê¸°ì¤€ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ìš”. ì…ë ¥ì„ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”.")